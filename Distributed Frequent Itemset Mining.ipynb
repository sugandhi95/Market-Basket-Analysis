{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project - 2 Final Version.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3u4RtY1pVgbK"
      },
      "source": [
        "Installing and importing the required modules:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCHYpGLGLWoA"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWcUejMNLlAv"
      },
      "source": [
        "import sys\n",
        "from pyspark import SparkContext, SparkConf\n",
        "import re\n",
        "import itertools\n",
        "from functools import reduce\n",
        "from itertools import chain\n",
        "from collections import OrderedDict"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnlkFqQpVlnM"
      },
      "source": [
        "Creating a Spark context:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cWmFeCwLluX"
      },
      "source": [
        "# create Spark context with necessary configuration\n",
        "sc = SparkContext(\"local\",\"PySpark Apriori\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsxTgCUxVo7t"
      },
      "source": [
        "Reading the file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22VT1zz8Lo9G"
      },
      "source": [
        "file = #<path to local txt file>"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7CNZIV9kcgq"
      },
      "source": [
        "Creating an RDD using a minimum of 30 partitions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p3EQ4G7MOpI"
      },
      "source": [
        "fileRDD = sc.textFile(file, minPartitions=30)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqyLRg5kY1Dt",
        "outputId": "21819a92-95bf-4b1f-bba6-dd8c15f9e5a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "fileRDD.take(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['FRO11987 ELE17451 ELE89019 SNA90258 GRO99222 ',\n",
              " 'GRO99222 GRO12298 FRO12685 ELE91550 SNA11465 ELE26917 ELE52966 FRO90334 SNA30755 ELE17451 FRO84225 SNA80192 ',\n",
              " 'ELE17451 GRO73461 DAI22896 SNA99873 FRO86643 ',\n",
              " 'ELE17451 ELE37798 FRO86643 GRO56989 ELE23393 SNA11465 ',\n",
              " 'ELE17451 SNA69641 FRO86643 FRO78087 SNA11465 GRO39357 ELE28573 ELE11375 DAI54444 ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX9hKC_0h49V"
      },
      "source": [
        "Converting all baskets to sets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqpbsmYflDTS"
      },
      "source": [
        "fileRDD = fileRDD.map(lambda x: x.split()) \\\n",
        "       .map(set)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9aDfCisJEOX"
      },
      "source": [
        "**Generating singletons above support level (>=85)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io1UQwdpmrWz"
      },
      "source": [
        "fullsingleRDD = fileRDD.flatMap(lambda x:x) \\\n",
        "                .map(lambda x: (x,1)) \\\n",
        "                .reduceByKey(lambda a,b: a+b) \\\n",
        "                .filter(lambda x: x[1] >= 85)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxcajUK9mxjz",
        "outputId": "8a847478-7fe4-4926-8a17-0683b4156961",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "fullsingleRDD.take(10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('GRO36567', 832),\n",
              " ('SNA66979', 703),\n",
              " ('FRO62970', 115),\n",
              " ('SNA14713', 188),\n",
              " ('FRO94523', 390),\n",
              " ('DAI88807', 1316),\n",
              " ('SNA96271', 1295),\n",
              " ('ELE15527', 332),\n",
              " ('SNA38068', 811),\n",
              " ('ELE55721', 169)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8IETC6WJcs6"
      },
      "source": [
        "Converting RDD to iterable form:\n",
        "exRDD = [a, b, c, d]\n",
        "to\n",
        "exRDD2 = [[a, b, c, d]]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rguCpsdwokot"
      },
      "source": [
        "ts = fullsingleRDD.filter(lambda x: x[1] >= 25) \\\n",
        "                .map(lambda x: x[0]).map(lambda x: (1, x)).reduceByKey(lambda a, b: a+\",\"+b).map(lambda x: x[1].split(\",\"))\n",
        "#.map(lambda x: (x[1]))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8TXSAqaLXOo"
      },
      "source": [
        "**Function to generate n-combinations from original basket RDD**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cHEn-KA176x"
      },
      "source": [
        "def comb(x, broad, n):\n",
        "  y = frozenset(x)\n",
        "  for item in broad:\n",
        "    if n == 2:\n",
        "      i = frozenset([item])\n",
        "    else:\n",
        "      i = frozenset(item)\n",
        "    if i.issubset(y):\n",
        "      comb = list(itertools.combinations(x, n))\n",
        "      try:\n",
        "        combs = [(tuple(sorted(x)),1) for x in comb]\n",
        "        return combs \n",
        "      except:\n",
        "        pass"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kgI0KHSR4oS"
      },
      "source": [
        "**Function to generate n-combinations from original basket RDD, for association rule mining:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFEe2x7LbH3d"
      },
      "source": [
        "def gen_comb(x, n):\n",
        "  if n == 1:\n",
        "    combos = list(x[0])\n",
        "  # Calculate combinations only when parameter n > 1  \n",
        "  elif n > 1:  \n",
        "    y = list(x[0])\n",
        "    combos = itertools.combinations(y,n)\n",
        "  cmbs = []\n",
        "  for c in combos:\n",
        "    if n == 1:\n",
        "      cmbs.append(((c), list(x)))\n",
        "    elif n > 1:\n",
        "      c = list(c)\n",
        "    # Returns ((<n-combination>, basket)) for every combination generated from basket\n",
        "      cmbs.append((tuple(c), list(x)))\n",
        "  return cmbs"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE7uCnrE3JQD"
      },
      "source": [
        "**Function to compute the confidence of each rule, and returning it only if it is >= the confidence parameter that is passed to the function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwdSURoV3I3N"
      },
      "source": [
        "def get_conf(x, c, n):\n",
        "  if n == 2:\n",
        "    denom = [x[0]]\n",
        "  else:\n",
        "    denom = list(x[0])\n",
        "  # Confidence (I -> j) = Support (I u j)/Support of I\n",
        "  conf = round(x[1][1][1]/x[1][0]*100, 2)\n",
        "  if conf >= c:\n",
        "    left = list(x[1][1][0])\n",
        "    lft = [x for x in left if x not in denom]\n",
        "    rule = str(denom)+\" -> \"+str(lft)+\" Confidence = \"+str(conf)+\"%\"\n",
        "    return (rule, conf)\n",
        "  else:\n",
        "    pass\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NaKTlPhSOgi"
      },
      "source": [
        "**Recursive Apriori function:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fJ8bh8kGi7E"
      },
      "source": [
        "# n starts at 2, because singletons have already been generated\n",
        "n = 2\n",
        "rulez = sc.parallelize([])\n",
        "# Function to use the apriori algorithm to generate association rules:\n",
        "# Parameters:\n",
        "# 1. prevRDD: RDD of frequent items from previous iteration that will be used to generate candidate item sets\n",
        "# 2. originalRDD: The original RDD that has all the baskets\n",
        "# 3. s: Support (>= 85)\n",
        "# 4. k: To generate k-combinations (4)\n",
        "# 5. n: n-combinations at which recursive algorithm starts\n",
        "# 6. c: Confidence threshold above which rules are deemed relevant (>= 90)\n",
        "# 7. rulez: RDD to store association rules\n",
        "def apriori(prevRDD, originalRDD, s, k, n, c, rulez):\n",
        "  if n <= k:\n",
        "    prev = prevRDD.map(lambda x: x[0])\n",
        "    # Broadcasting frequent n-combinations to use\n",
        "    freq_broad = sc.broadcast(prev.collect())\n",
        "    # n-combinations of frequent items\n",
        "    combos = originalRDD.map(lambda x: comb(x, freq_broad.value, n)) \\\n",
        "                        .filter(bool) \\\n",
        "                        .flatMap(lambda x: x) \\\n",
        "                        .reduceByKey(lambda a, b: a+b) \\\n",
        "                        .filter(lambda x: x[1] >= s)\n",
        "    # List of frequent items that will be used in subsequent steps to generate the next order of candidate items\n",
        "    frequent = combos.map(lambda x: x[0]) \\\n",
        "                         .flatMap(lambda x:x) \\\n",
        "                         .map(lambda x: (1, x)) \\\n",
        "                         .reduceByKey(lambda a, b: a+\",\"+b) \\\n",
        "                         .map(lambda x: x[1].split(\",\")) \n",
        "    # Association rules\n",
        "    # 1. Exploding frequent items for subsequent join with singles\n",
        "    explRDD = combos.map(lambda x: gen_comb(x,(n-1))) \\\n",
        "                    .flatMap(lambda x:x) \\\n",
        "                    .map(lambda x: (x[0], tuple(x[1]))) \n",
        "    # 2. Conducting an inner join between singles and truly frequent items\n",
        "    jointRDD = prevRDD.join(explRDD)\n",
        "    # 3. Getting association rules that have a confidence above the threshold\n",
        "    assocRD = jointRDD.map(lambda x: get_conf(x, c, n))\\\n",
        "                      .filter(bool) \\\n",
        "                      .filter(lambda x: x[1] >= c) \\\n",
        "                      .sortBy(lambda x: x[1], ascending = False) \\\n",
        "                      .map(lambda x: x[0])\n",
        "    rulez = rulez.union(assocRD)\n",
        "    freq_broad.unpersist()\n",
        "    return apriori(combos, originalRDD, s, k, n+1, c, rulez)\n",
        "  else:\n",
        "    return rulez"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWPMwBb9O24y"
      },
      "source": [
        "# Generating association rules using:\n",
        "# 1. The RDD of frequent singletons, the original RDD\n",
        "# 2. The original RDD\n",
        "# 3. Support = 85\n",
        "# 4. Desired number of items in frequent itemsets = 4\n",
        "# 5. Starting at pairs (2)\n",
        "# 6. Confidence = 90%\n",
        "# 7. rulez to store the association rules to save to a text file later\n",
        "rools = apriori(fullsingleRDD, fileRDD, 85, 4, 2, 90, rulez)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zfowhAtoTr6"
      },
      "source": [
        "Saving the generated association rules to a local file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNCemB6vtO25"
      },
      "source": [
        "rools.coalesce(1).saveAsTextFile(<path to local folder>)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZzObGZ-PNhv",
        "outputId": "74141e65-82ee-469d-eaca-ebd10220d486",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rools.take(5)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"['DAI93865'] -> ['FRO40251'] Confidence = 100.0%\",\n",
              " \"['GRO85051'] -> ['FRO40251'] Confidence = 99.92%\",\n",
              " \"['GRO38636'] -> ['FRO40251'] Confidence = 99.07%\",\n",
              " \"['ELE12951'] -> ['FRO40251'] Confidence = 99.06%\",\n",
              " \"['DAI88079'] -> ['FRO40251'] Confidence = 98.67%\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}